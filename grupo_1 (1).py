# -*- coding: utf-8 -*-
"""Grupo_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P19UD9ZMZjdiO6Sn-cwj9dgIEIc2IeAQ

# Importar libros
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""# Base de datos"""

df = pd.read_csv("https://raw.githubusercontent.com/bssanchezlopez/Grupo_1/refs/heads/main/synthetic_fraud_dataset.csv")

# Convertir Timestamp a datetime
df["Timestamp"] = pd.to_datetime(df["Timestamp"], dayfirst=True, errors="coerce")

# Crear variables temporales
df["Year"] = df["Timestamp"].dt.year
df["Month"] = df["Timestamp"].dt.month
df["Day"] = df["Timestamp"].dt.day
df["Hour"] = df["Timestamp"].dt.hour
df["Weekday"] = df["Timestamp"].dt.weekday

# Drop del timestamp original
df = df.drop("Timestamp", axis=1)

# One-hot encoding
low_cardinality = [
    "Transaction_Type", "Device_Type", "Location",
    "Merchant_Category", "Card_Type", "Authentication_Method"
]

df = pd.get_dummies(df, columns=low_cardinality, drop_first=True)

# Drop de columnas no numéricas
df = df.drop(["Transaction_ID", "User_ID"], axis=1)

# Separar variables
X = df.drop(["Fraud_Label","Risk_Score" ],axis=1)
y = df["Fraud_Label"]

len(df)

"""# Entrenar datos"""

# Train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123,shuffle=True)

# Verificar columnas
print(X_train.columns)

"""# KNN"""

# 5. Entrenar modelo
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Predicción
y_pred = knn.predict(X_test)

"""# DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(
    max_depth=3,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=123
)
dt.fit(X_train, y_train)

dt_acc = dt.score(X_test, y_test)
print("Decision Tree Accuracy:", dt_acc)

"""# SVM"""

from sklearn.svm import SVC

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Escalar variables"""

svm = SVC(kernel="rbf", random_state=123)
svm.fit(X_train_scaled, y_train)

svm_acc = svm.score(X_test_scaled, y_test)
print("SVM Accuracy:", svm_acc)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

models = {
    "KNN": knn,
    "SVM": svm,
    "Decision Tree": dt
}

for name, model in models.items():
    print(f"\n===== {name} =====")

    y_pred = model.predict(X_test)

    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred, average='weighted'))
    print("Recall:", recall_score(y_test, y_pred, average='weighted'))
    print("F1 Score:", f1_score(y_test, y_pred, average='weighted'))

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

# Evaluación
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nMatriz de confusión:\n", confusion_matrix(y_test, y_pred))
print("\nReporte de clasificación:\n", classification_report(y_test, y_pred))